---
layout: post
title: "[Publication] Reinforcement Learning in Education: A Multi-Armed Bandit Approach"
date: 2022-11-01
image: "https://github.com/dsfsi/dsfsi.github.io/raw/master/images/2022-11-01-Pub_RL-in-Education.PNG"
excerpt: "Paper by Herkulaas MvE Combrink, Vukosi Marivate, Benjamin Rosman"
---
## Members
Herkulaas Combrink, Vukosi Marivate, Benjami Rosman 

## Abstract
Advances in reinforcement learning research have demonstrated the ways in which different agent-based models can learn how to optimally perform a task within a given environment. Reinforcement leaning solves unsupervised problems where agents move through a state-action-reward loop to maximize the overall reward for the agent, which in turn optimizes the solving of a specific problem in a given environment. However, these algorithms are designed based on our understanding of actions that should be taken in a real-world environment to solve a specific problem. One such problem is the ability to identify, recommend and execute an action within a system where the users are the subject, such as in education. In recent years, the use of blended learning approaches integrating face-to-face learning with online learning in the education context, has in-creased. Additionally, online platforms used for education require the automation of certain functions such as the identification, recommendation or execution of actions that can benefit the user, in this sense, the student or learner. As promising as these scientific advances are, there is still a need to conduct research in a variety of different areas to ensure the successful deployment of these agents within education systems. Therefore, the aim of this study was to contextualise and simulate the cumulative reward within an environment for an intervention recommendation problem in the education context.
## Publications
* H. Combrink, V. Marivate, B. Rosman. **Reinforcement Learning in Education: A Multi-Armed Bandit Approach**, *   EAI AFRICATEK 2022 Conference, 2022. [ML]  <> [[Paper URL](https://arxiv.org/abs/2211.00779)] **DOI:** [10.48550/arXiv.2211.00779](https://doi.org/10.48550/arXiv.2211.00779) 